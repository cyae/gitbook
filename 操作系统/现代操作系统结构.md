---
date created: 2023-03-08 19:51
---

#OS

## 1. CPU 缓存

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004551232-843733723.png)

- CPU 缓存分为 3 级结构: 寄存器 -> L1 缓存(数据缓存 + 指令缓存) -> L2 缓存 -> L3 共享缓存
- 缓存的最小单位: 缓存行(64kb), 这意味着对于内存连续的数据结构, 一次会将 64kb 的元素载入数据缓存
  - 好处是: 可以用来提升缓存命中率, 比如二维数组的行优先好于列优先遍历, 比如将同种类型的运算符聚类, 以充分利用指令缓存加速分支预测器
  - 坏处是: 造成伪共享, 降低 CAS 的效率, 可以使用 padding 消除
- 对于多核 CPU, 由于 L1L2 缓存不能共享, 因此也造成多线程被调度算法分到不同核上, 缓存失效的问题
- 正如 DB 会在合适的时间将内存页刷回磁盘一样, CPU 也会将缓存刷回内存
  - 写直达: 实时双写, 保证 CPU 缓存和内存的强一致性, 影响性能
  - 写回: 保证最终一致性, 缓存命中时标记为脏行但不刷内存, 缓存不命中且缓存行为脏才刷内存
    - 那么在不一致的窗口, 若其他 CPU 核上的线程读取内存脏数据, 就造成不一致
    - 基于总线嗅探的 MESI 协议: 对所有 CPU 核, 保证缓存更改的可见性和有序性

## 2. 硬中断 vs 软中断

- 中断处理是内核的一个功能, 负责处理南向硬件的请求, 与文件, 网络, 内存管理等平级
- 由于中断会阻塞用户进程, 因此有两种方法减小影响:
  - 中断屏蔽: 中断可以嵌套, 这样切换上下文次数多了影响效率, 中断屏蔽指令可以让中断不被抢占, 减少中断总时间
  - 中断拆分: 类似标记脏数据思想, 先被动接收中断, 但不立即处理, 然后由内核挑时间延迟集中处理

## 3. 巨内核 vs 微内核

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004600746-1337099853.png)

- 内核是对硬件指令的统一封装
- linux 是巨内核, 这意味着所有封装动作都在内核态完成
  - 缺点是封装内部的各功能耦合度高, 可移植性差, 优点是核内 inline 调用无需频繁切换, 性能高
- 微内核只在内核态封装最基本的调度, 虚拟内存, 中断等硬件功能, 其他功能如驱动, 文件系统全部交给用户态实现
  - 优点是可移植性高, 自己在用户态实现的功能可以解耦, 缺点是用户请求某些硬件功能时需频繁切换到内核态, 性能差
- 类比 TCP 的强治理 vs UDP 的弱治理

## 4. 虚拟内存

- 通过内存管理单元 MMU, 将不同进程的物理内存空间做屏蔽
- 分段

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004610209-1632398551.png)

- 会产生段外碎片和段内碎片
  - 段外碎片: 需要将零散的段放到硬盘 swap 区, 再写回内存, 类似 GC 的复制算法
  - 由于需要 IO 与硬盘交互, 速度很慢, 产生抖动
  - 段内碎片无法避免
- 分页

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004616641-1881505055.png)

- 没有外部碎片, 内部碎片不超过单页大小
- 额外需要 MMU 管理页表, 页表占一定空间
- 根据局部性原理, 使用多级页表动态加载需要的页

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004627166-834163332.png)

- 添加快表做缓存
- 段页式
  - 在按进程逻辑块分段的基础上, 将每个段分页
    ![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004634950-197069020.png)

## 5. 页面置换算法

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004643055-216330307.png)

- 在缺页时, 假如第 4 步无法找到内存空闲页, 就需要换出脏页
- 目标: 减少总体置换次数
  - 最佳置换, 未来最少使用
  - FIFO
  - LRU, 最久未使用
  - LFU, 最少使用
  - 时钟, 沿途访问过的标为未访问, 直到遇到未访问的

## 6. 进程 vs 线程

- 单核 CPU 通过中断实现进程切换, 从而达到并发效果
- 多核 CPU 并行执行

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004652415-895756112.png)

- 挂起: 大量处于阻塞或就绪状态的进程会占据内存空间, 因此将其换出到磁盘
- 使用链表实现阻塞队列, 就绪队列, 单元是 PCB

线程之于进程, 就好比容器之于虚拟机, Runnable 之于 Thread:

- 进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位；
- 进程拥有⼀个完整的资源平台，⽽线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞、执⾏三种基本状态，同样具有状态之间的转换关系；
- 线程能减少并发执⾏的时间和空间开销；
- 线程的创建时间⽐进程快，因为进程在创建的过程中，还需要资源管理信息，⽐如内存管理信息、⽂件管理信息，⽽线程在创建的过程中，不会涉及这些资源管理信息，⽽是共享它们；
- 线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多；
- 同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着
- 同⼀个进程的线程都具有同⼀个⻚表，那么在切换的时候不需要切换⻚表。⽽对于进程之间的切换，切换的时候要把⻚表给切换掉，⽽⻚表的切换过程开销是⽐较⼤的；
- 由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更⾼了

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004659193-385313222.png)

进程 1, 4: 内核线程
![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004705688-1996437565.png)

进程 2: 用户线程
![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004713015-1124006425.png)

进程 3: 轻量级线程

进程 5: 混合线程

## 7. 僵尸进程 vs 孤儿进程 vs 守护进程

- 正常情况下, 子进程结束后, 其大部分资源会被内核回收, 只留下现场信息(PID, timestamp, status)用于父进程调用 wait()时获取子进程状态
- 僵尸进程: 父进程未调用 wait(), 子进程的现场信息删不掉
  - 解决方法, 杀掉父进程, 让 init 统一处理
- 孤儿进程: 父进程结束时, 调用 wait()发现子进程还在运行, 那么父进程通知 init 进程去回收子进程的资源, 然后挂掉. 在 init 收到通知并杀死子进程前的时间里, 称为孤儿进程
- 守护进程: 开机就运行, 一直在跑, 杀不死(杀死后立即重生)

## 8. 进程线程调度算法

- FIFO
- SJF
- 高响应比优先

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004722241-1390752640.png)

- RR
- 高优先级
- 多级反馈队列 = RR + 高优先级

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004728852-728348324.png)

## 9. 磁盘调度算法

- 先来先服务 = FIFO
- 最短寻道时间 = SJF
- 扫描/循环扫描/LOOK/循环 LOOK = RR

## 10. 进程通信

### FIFO 管道

- 父进程创建管道 -> fork -> 父子进程间通信

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004736067-1764586610.png)

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004742514-1455085198.png)

- shell 是所有进程的父进程

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004809393-63597475.png)

### 消息队列

### 共享内存

- 虚拟内存技术将不同进程的内存空间隔离
- 共享内存则共享内存空间
- 比如 static 变量, 临界资源

### 信号

- kill -l

### 信号量

- P 消费, V 生产

### Socket

- 分 TCP/UDP

## 11. 单点锁模型

- 生产消费者
- 哲学家进餐
- 读写者

## 12. 死锁

- 互斥访问
- 不可剥夺
- 持有等待(当线程被阻塞时, 不会释放持有的临界资源, 即使该线程现在不使用)
- 循环等待

## 13. 阻塞 vs 非阻塞

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004819073-1673548066.png)

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004824729-810426818.png)

- 以上两种都是同步式调用, 因为最后的拷贝阶段(内核缓冲区->用户进程缓冲区)需要用户进程阻塞, 区别仅在于内核准备数据阶段(磁盘->内核缓冲区)是阻塞还是轮询

## 14. I/O 多路复⽤

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004830626-545198666.png)

- 上边仍然是同步式调用, 因为最后的拷贝阶段需要用户进程阻塞

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004836491-351172236.png)

- 真正的异步式调用, 用户进程将最后的拷贝阶段主动权让给内核, 由内核拷贝完后通知, 用户进程在全部时间无阻塞

## 15. 直接内存访问 DMA

- 传统 IO, 无 DMA, CPU 需承担数据桥的拷贝工作, 拷贝期间 CPU 一直被占用

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004845510-1899625496.png)

- DMA, 将数据桥的角色分离出来, 但将数据从磁盘⾼速缓存拷贝到用户缓冲区仍经过 CPU, 因为涉及到上下文切换, 只有 CPU 有最高权限
- 涉及 2 次用户态到内核态的上下文切换, 1 次 DMA 拷贝(磁盘 -> 磁盘⾼速缓存), 1 次 CPU 拷贝(磁盘⾼速缓存 -> 用户进程缓冲区)

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004853770-534843201.png)

- DMA 类似 MMU, 那么磁盘高速缓存则对应快表, 假如命中, 则只需要 1 次 CPU 拷贝

## 16. 零拷贝

- 业务场景:
  - 下载文件, 先从磁盘 read 到用户进程, 再拷到 socket 发给客户端, 不在用户进程允许对载入的磁盘里的文件进行再加工, 比如压缩, 转义
  - Kafka -> NIO -> Channel.transferTo() -> sendfile
  - Nginx

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004901348-1849086869.png)

- 共享内存 mmap, 减少 1 次 CPU 拷贝

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004907020-1226105455.png)

- sendfile -> 减少 1 次 CPU 拷贝 + 2 次上下文切换

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004912705-1700810803.png)

- 若网卡支持 SG-DMA, 则能再减少 1 次 CPU 拷贝

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004920681-1021085045.png)

- 若磁盘高速缓存命中, 则能再减少 1 次 DMA 拷贝 ①
- 但假如传输的是大文件, 那么磁盘高速缓存区很快被占满, 而且命中率很低, 则 ①DMA 拷贝 不可回避
  - 解决方案: 直接绕过磁盘高速缓存, 重新启用用户缓存取而代之. 同时, 使用异步 IO, 让内核拷完后通知用户进程, 减少用户阻塞

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004929001-137195870.png)

- Nginx 大小文件传输阈值:

```nginx
location /path/ {
 sendfile on; // 启用零拷贝
 aio on; // 启用异步IO
 directio 1024m; // 阈值, 小于时用零拷贝
}
```

## 17. 多线程 socket 模型

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004937581-1288849754.png)

- 问题在于, 线程池里的子线程与 socket 队列一一对应, 无法支撑 C10K

- 思路: 一个子线程对应多 socket, 采用类似并发的方式快速切换, 产生多路复用效果.

  - 这要求 socket 是非阻塞的, 否则在 read -> 业务处理 -> socket send 时一旦发生阻塞, 线程也阻塞, 无法响应对应的其他 socket

- 多路复用框架, 非阻塞同步式: 将所有 socket 放入内核, 然后等待事件, 最后将产生事件的 socket 返回给对应单一的用户态子线程处理

  - select, 在内核态进行循环轮询, 发生事件后标记该 socket 为可读/写, 然后将所有 socket 拷回用户态, 再通过轮询找到被标记 socket, 最后开始处理
    - 底层数据结构 bitMap, 最大 1024 个 socket
  - poll, 将底层数据结构改为链表, 数量不受限制
  - epoll, 底层数据结构改为红黑树, 同时维护一个链表, 用来记录被触发的 socket

  ![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004944747-1689772478.png)

- 多路复用框架, 非阻塞异步式: Windows 下的 IOCP

## 18. Reactor/Dispatcher vs Proactor

- Reactor/Dispatcher 即对非阻塞同步式 IO 进行封装

  - reactor 负责监听和分发事件
  - 单线程/线程池负责处理事件
  - 单 Reactor + 单线程

  ![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004952423-50558755.png)

  - handler 负责处理事件
  - Redis6.0 以前采用此方案
  - 单 Reactor + 线程池\<Handler\>

  ![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901004958613-165148077.png)

  - handler 负责转发事件到 processor 子线程
  - Redis6.0 以后的解析部分采用此方案, 多个 Handler 子线程负责解析命令, 真正执行命令还是主线程单独执行
  - 单 Reactor 既负责北向监听, 又负责南向 Acceptor 建立连接, 还要负责将处理结果返回给客户端, 易单点瓶颈, 因此提出多 Reactor + 单线程

  ![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901005005213-1212213415.png)

  - 主 Reactor 只负责监听和建立连接, 处理结果返回交给各个子 Reactor
  - Netty, Memcache, Nginx(子 Reactor 建立连接)

- Proactor

![image](https://img2022.cnblogs.com/blog/2827284/202209/2827284-20220901005011724-1143370119.png)
